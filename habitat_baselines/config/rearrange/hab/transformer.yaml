VERBOSE: False
BASE_TASK_CONFIG_PATH: configs/tasks/rearrange/rearrange.yaml
TRAINER_NAME: "transformer"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
VIDEO_OPTION: ['disk']
TENSORBOARD_DIR: "tb"
VIDEO_DIR: ""
VIDEO_FPS: 30
VIDEO_RENDER_TOP_DOWN: False
VIDEO_RENDER_ALL_INFO: True
VIDEO_RENDER_VIEWS:
  - "THIRD_RGB_SENSOR"
SENSORS: ["HEAD_DEPTH_SENSOR"]
TEST_EPISODE_COUNT: -1
EVAL_CKPT_PATH_DIR: ""
NUM_ENVIRONMENTS: 8
WRITER_TYPE: 'tb'
# Visual sensors to include
CHECKPOINT_FOLDER: ""
NUM_UPDATES: 1000
TEST_INTERVAL: 20
TOTAL_NUM_STEPS: -1.0
LOG_INTERVAL: 1
NUM_CHECKPOINTS: -1
CHECKPOINT_INTERVAL: 100
FORCE_TORCH_SINGLE_THREADED: True
EVAL_KEYS_TO_INCLUDE_IN_NAME: ['success']
EVAL:
  SPLIT: "eval"
  USE_CKPT_CONFIG: True

RL:

  preemption:
    save_resume_state_interval: 20
  POLICY:
      name: "TransformerResNetPolicy"
      action_distribution_type: "mixed"
      ACTION_DIST:
        discrete_arm: false
        discrete_base: false
        use_std_param: true
        temperature: 1.0
      offline: true
      include_visual_keys: ["robot_head_depth"]
      train_planner: true
      train_control: true
      temperature: 1.0
      

  REWARD_MEASURE: "composite_reward"
  SUCCESS_MEASURE: "composite_success"
  SUCCESS_REWARD: 100.0
  SLACK_REWARD: -0.01

  TRAJECTORY_DATASET:
    trajectory_dir: ""
    dataset_size: 10000
    files_per_load: 5
    queue_size: 1

  VALIDATION_DATASET:
    trajectory_dir: ""
    dataset_size: -1
    files_per_load: 5
    queue_size: 1

  TRANSFORMER:
    lr: 6.0E-5
    eps: 1.0E-5
    grad_norm_clip: 0.5
    use_linear_lr_decay: True
    batch_size: 230
    num_workers: 2

    warmup_updates: 200

    return_to_go: 100
    context_length: 30
    max_episode_step: 500
    # model_type: "reward_conditioned"
    model_type: "bc"
    n_head: 8
    n_layer: 2
    freeze_layer: [] #
    reg_flags: 
      outer_dropout: true
      outer_layernorm: true
      attention_dropout: true
      attention_layernorm: true
      feedforward_dropout: true
      feedforward_layernorm: true
    hidden_size: 512
    backbone: resnet18
    hidden_size: 512

    # Use double buffered sampling, typically helps
    # when environment time is similar or large than
    # policy inference time during rollout generation
    use_double_buffered_sampler: False

    sync_frac: 0.6
    # The PyTorch distributed backend to use
    distrib_backend: NCCL
    # Visual encoder backbone
    pretrained_weights: ""
    # Initialize with pretrained weights
    pretrained: False
    # Initialize just the visual encoder backbone with pretrained weights
    pretrained_encoder: False
    # Whether or not the visual encoder backbone will be trained.
    train_encoder: True

    # Model parameters
    backbone: resnet18 # resnet18